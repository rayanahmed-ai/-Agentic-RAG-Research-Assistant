# ğŸ§  Agentic RAG Research Assistant **A ReAct-style, Agent-Orchestrated System for Grounded Research Question Answering** --- ## ğŸ“Œ Overview Large Language Models (LLMs) are powerful but unreliable for research tasks due to hallucinations and lack of source grounding. This project implements an **agentic Retrieval-Augmented Generation (RAG) system** that behaves like a **research assistant**, not a chatbot. It reasons about queries, retrieves evidence from research papers, and produces **strictly grounded answers**. If the answer is not explicitly supported by the paper, the system refuses to answer. --- ## ğŸ¯ Objectives - Prevent hallucinations in research Q&A - Enforce citation-grounded answers - Implement ReAct-style reasoning using agents - Provide a production-ready research assistant API --- ## ğŸ§  Key Features - **Agent-orchestrated architecture (LangGraph)** - **ReAct-style reasoning loop (Reason â†’ Act â†’ Observe â†’ Answer)** - **Strict hallucination control** - **FAISS-based semantic retrieval** - **Fine-tuned TinyLlama for academic responses** - **FastAPI backend** - **Dockerized and Azure-ready** --- --- ## ğŸ§  Agent Design (ReAct-style) This project uses an **implicit ReAct architecture** suitable for production: 1. **Planner Agent** - Analyzes the query - Decides whether paper retrieval is required 2. **Retriever** - Performs similarity search using FAISS - Returns top-k relevant paper chunks 3. **Observation** - Aggregates retrieved context - Ensures only paper content is passed forward 4. **Executor** - Uses the fine-tuned LLM - Generates a grounded answer or refuses Unlike chat-based ReAct, this design is **deterministic, auditable, and safe**. --- ## ğŸ”§ Tech Stack | Layer | Technology | |-----|-----------| | LLM | TinyLLaMA 1.1B | | Fine-tuning | PEFT (LoRA) | | Agents | LangGraph | | Retrieval | FAISS | | Embeddings | sentence-transformers | | Backend | FastAPI | | PDF Parsing | PyPDF | | Containerization | Docker | | Cloud | Azure-ready | --- ## ğŸ§  LoRA Fine-Tuning - **Base Model:** `TinyLlama/TinyLlama-1.1B-Chat` - **Objective:** Research-style, concise, grounded answers - **Dataset:** Custom research Q&A samples - **Epochs:** Minimal (prototype-level due to GPU constraints) - **Purpose:** Behavioral alignment (not knowledge injection) The model is **not trained to know papers**, only to **answer responsibly** using provided context. --- ## ğŸ§ª Example Queries (Guaranteed) These queries will be answered **if stated in the paper**: - Who are the authors of the paper? - What architecture does the paper introduce? - Does the model remove recurrence? - What mechanism replaces convolutions? - What is the main contribution? --- ## âŒ Example Refusals (Expected Behavior) - Why is this model better than GPT? - What are the future implications? - How does this compare to other models? - What is the real-world impact? If the paper does not explicitly state it â†’ **Refusal**. --- ## ğŸ“Š Evaluation Philosophy This project prioritizes: - Grounded correctness - Refusal accuracy - Hallucination resistance - Research-style clarity There are **no artificial accuracy scores** â€” correctness > verbosity. --- ## ğŸ§‘â€ğŸ“ Internship Value This project demonstrates: - Agentic AI system design - ReAct-style reasoning (production-safe) - Retrieval-Augmented Generation - Hallucination mitigation - LLM fine-tuning with LoRA - Backend + ML integration - Cloud-ready ML systems Suitable for: - AI Research Internships - ML Engineering Internships - Applied AI Roles --- ## ğŸ“¦ Installation & Usage ### 1. Install Dependencies ```bash pip install -r requirements.txt# -Agentic-RAG-Research-Assistant
